---
excerpt: movie recommendation with deep learning
author_profile: true
title:  "Collaborative Filtering with Pytorch Embedding"
categories:
  - data science
tags:
  - regression
  - machine learning
  - data science
  - deep learning
header:
  overlay_image: /assets/images/movies.jpg
  teaser: /assets/images/movies.jpg
  overlay_filter: 0.5
---
```python
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torch.utils.data as data_utils
import numpy as np
import math
from sklearn.model_selection import train_test_split
import copy
import matplotlib.pyplot as plt
import torch.utils.data as data_utils
from sklearn.decomposition import PCA
```

# Prepare the dataset


```python
# load the rating data
path = "/content/ml-100k/"
ratings = pd.read_csv(path + 'u.data', delimiter='\t', header=None,
                      usecols=(0,1,2), names=['user','movie','rating'])
ratings.head()
```





  <div id="df-1f88d227-8639-4c74-97e4-acc00b21fec6">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user</th>
      <th>movie</th>
      <th>rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>196</td>
      <td>242</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>186</td>
      <td>302</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>22</td>
      <td>377</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>244</td>
      <td>51</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>166</td>
      <td>346</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1f88d227-8639-4c74-97e4-acc00b21fec6')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-1f88d227-8639-4c74-97e4-acc00b21fec6 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-1f88d227-8639-4c74-97e4-acc00b21fec6');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
# load the movie data
movies = pd.read_csv(path + 'u.item',  delimiter='|', encoding='latin-1',
                     usecols=(0,1), names=('movie','title'), header=None)
movies.head()
```





  <div id="df-bb4c734f-58b0-4d44-a890-82947824a33a">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movie</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Toy Story (1995)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>GoldenEye (1995)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Four Rooms (1995)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Get Shorty (1995)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Copycat (1995)</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-bb4c734f-58b0-4d44-a890-82947824a33a')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-bb4c734f-58b0-4d44-a890-82947824a33a button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-bb4c734f-58b0-4d44-a890-82947824a33a');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
# merge the dataset
ratings = ratings.merge(movies)
ratings.head()
```





  <div id="df-cc4ee125-2b30-4a0a-9064-7be2a380dcfb">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user</th>
      <th>movie</th>
      <th>rating</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>196</td>
      <td>242</td>
      <td>3</td>
      <td>Kolya (1996)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>63</td>
      <td>242</td>
      <td>3</td>
      <td>Kolya (1996)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>226</td>
      <td>242</td>
      <td>5</td>
      <td>Kolya (1996)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>154</td>
      <td>242</td>
      <td>3</td>
      <td>Kolya (1996)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>306</td>
      <td>242</td>
      <td>5</td>
      <td>Kolya (1996)</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-cc4ee125-2b30-4a0a-9064-7be2a380dcfb')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-cc4ee125-2b30-4a0a-9064-7be2a380dcfb button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-cc4ee125-2b30-4a0a-9064-7be2a380dcfb');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
ratings['user'] = ratings['user'] -1
ratings['movie'] = ratings['movie'] -1
```


```python
movies['movie'] = movies['movie'] -1
```


```python
dataset_sizes = ratings.shape
dataset_sizes
```




    (100000, 4)




```python
n_users = len(ratings["user"].unique())
n_movies = len(ratings["movie"].unique())
n_users, n_movies
```




    (943, 1682)




```python
# movies with max. number of ratings
ratings["title"].value_counts()[:20]
```




    Star Wars (1977)                    583
    Contact (1997)                      509
    Fargo (1996)                        508
    Return of the Jedi (1983)           507
    Liar Liar (1997)                    485
    English Patient, The (1996)         481
    Scream (1996)                       478
    Toy Story (1995)                    452
    Air Force One (1997)                431
    Independence Day (ID4) (1996)       429
    Raiders of the Lost Ark (1981)      420
    Godfather, The (1972)               413
    Pulp Fiction (1994)                 394
    Twelve Monkeys (1995)               392
    Silence of the Lambs, The (1991)    390
    Jerry Maguire (1996)                384
    Chasing Amy (1997)                  379
    Rock, The (1996)                    378
    Empire Strikes Back, The (1980)     367
    Star Trek: First Contact (1996)     365
    Name: title, dtype: int64




```python
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
```


```python
target = torch.tensor(ratings['rating'].values.astype(np.float32), device=device)[..., np.newaxis]
features = torch.tensor(ratings.drop(['rating', 'title'], axis = 1).values.astype(np.int32), device=device) 
```


```python
# split datasets
data_tensor = data_utils.TensorDataset(features, target)
train_data, test_data = train_test_split(data_tensor, test_size=0.2, random_state=42)
len(train_data), len(test_data)
```




    (80000, 20000)




```python
bs = 100
train_loader = data_utils.DataLoader(train_data, batch_size=bs, shuffle=True)
test_loader = data_utils.DataLoader(test_data, batch_size=bs, shuffle=True)
```

# Define the model


```python
def sigmoid_range(x, low, high):
    "Sigmoid function with range `(low, high)`"
    return torch.sigmoid(x) * (high - low) + low
```


```python
class EmbeddingNet(nn.Module):
  def __init__(self, n_users, n_movies, n_factors = 10, y_range=(0,5.5)):
      super().__init__()
      self.user_factors = nn.Embedding(n_users, n_factors)
      self.user_bias = nn.Embedding(n_users, 1)
      self.movie_factors = nn.Embedding(n_movies, n_factors)
      self.movie_bias = nn.Embedding(n_movies, 1)
      self.y_range = y_range
  def forward(self, user_idx, movie_idx):
      users = self.user_factors(user_idx)
      movies = self.movie_factors(movie_idx)
      res = (users * movies).sum(dim=1, keepdim=True)
      res += self.user_bias(user_idx) + self.movie_bias(movie_idx)
      return sigmoid_range(res, *self.y_range)
```


```python
# training loop parameters
lr = 3e-3
wd = 3e-4

n_epochs = 30
patience = 20
no_improvements = 0
best_loss = np.inf
best_weights = None
n_factors = 50

model = EmbeddingNet(n_users, n_movies, n_factors).to(device)

criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.5, total_iters=10)
```


```python

```


```python
model
```




    EmbeddingNet(
      (user_factors): Embedding(943, 50)
      (user_bias): Embedding(943, 1)
      (movie_factors): Embedding(1682, 50)
      (movie_bias): Embedding(1682, 1)
    )




```python
train_history = []
val_history = []
lr_history = []

best_loss = 1e3
for i in range(n_epochs):
  train_loss = 0
  n_batches = 0
  # train phase
  for features, targets in train_loader:
      optimizer.zero_grad()
      output = model(features[...,0], features[...,1])
      loss = criterion(output, targets)
 
      loss.backward()
      optimizer.step()
      
      train_loss += loss.detach()
      n_batches += 1

  #scheduler.step()
      
  train_loss = train_loss/n_batches
  train_history.append(train_loss)
  lr_history.append(scheduler.get_last_lr())
  
  # validation
  n_batches = 0
  val_loss = 0
  with torch.no_grad():
    for features, targets in test_loader:
      output = model(features[...,0], features[...,1])
      loss = criterion(output, targets)
      val_loss += loss
      n_batches += 1  
  val_loss = val_loss/n_batches
  val_history.append(val_loss)
  if (val_loss < best_loss):
    best_weights = copy.deepcopy(model.state_dict())
    best_loss = val_loss
  print("Epoch {}, train_loss: {}, val_loss: {}"    
        .format(i, train_loss.cpu().numpy(), val_loss.cpu().numpy()))
#model.load_state_dict(best_weights)
```

    Epoch 0, train_loss: 7.457712173461914, val_loss: 7.2247538566589355
    Epoch 1, train_loss: 6.389175891876221, val_loss: 6.712790012359619
    Epoch 2, train_loss: 5.461848258972168, val_loss: 6.160996913909912
    Epoch 3, train_loss: 4.655222415924072, val_loss: 5.5575456619262695
    Epoch 4, train_loss: 3.8971118927001953, val_loss: 4.903194904327393
    Epoch 5, train_loss: 3.1772820949554443, val_loss: 4.215761184692383
    Epoch 6, train_loss: 2.510025978088379, val_loss: 3.52919340133667
    Epoch 7, train_loss: 1.9204601049423218, val_loss: 2.887474298477173
    Epoch 8, train_loss: 1.4384808540344238, val_loss: 2.3278536796569824
    Epoch 9, train_loss: 1.0748509168624878, val_loss: 1.8732044696807861
    Epoch 10, train_loss: 0.8238030076026917, val_loss: 1.5306777954101562
    Epoch 11, train_loss: 0.669340193271637, val_loss: 1.2942407131195068
    Epoch 12, train_loss: 0.5864189267158508, val_loss: 1.1392508745193481
    Epoch 13, train_loss: 0.5462559461593628, val_loss: 1.041947603225708
    Epoch 14, train_loss: 0.5291838049888611, val_loss: 0.9798373579978943
    Epoch 15, train_loss: 0.5221965312957764, val_loss: 0.9406192302703857
    Epoch 16, train_loss: 0.5192626714706421, val_loss: 0.9124849438667297
    Epoch 17, train_loss: 0.5155234932899475, val_loss: 0.8936429023742676
    Epoch 18, train_loss: 0.5117744207382202, val_loss: 0.8807430267333984
    Epoch 19, train_loss: 0.5071832537651062, val_loss: 0.8699108362197876
    Epoch 20, train_loss: 0.5019437074661255, val_loss: 0.8627417087554932
    Epoch 21, train_loss: 0.49624019861221313, val_loss: 0.8580852746963501
    Epoch 22, train_loss: 0.4914500415325165, val_loss: 0.8545466661453247
    Epoch 23, train_loss: 0.4865557551383972, val_loss: 0.8525440692901611
    Epoch 24, train_loss: 0.4807068109512329, val_loss: 0.8509074449539185
    Epoch 25, train_loss: 0.47658705711364746, val_loss: 0.849090039730072
    Epoch 26, train_loss: 0.4731192886829376, val_loss: 0.8473911285400391
    Epoch 27, train_loss: 0.46931734681129456, val_loss: 0.8465709090232849
    Epoch 28, train_loss: 0.4657156467437744, val_loss: 0.8458096385002136
    Epoch 29, train_loss: 0.4617335796356201, val_loss: 0.8460785746574402
    


```python
model.load_state_dict(best_weights)
```




    <All keys matched successfully>




```python
train_history = np.asarray(train_history)
val_history = np.asarray(val_history)
lr_history = np.asarray(lr_history) 
fig = plt.figure()
plt.plot(train_history)
plt.plot(val_history)
```




    [<matplotlib.lines.Line2D at 0x7f81a0f41b10>]




    
![png](/assets/images/cf/output_22_1.png)
    


# Visualize the Results


```python
def get_movie(ids):
    return [movies.loc[id]["title"] for id in ids]
```


```python
 with torch.no_grad():
    for features, targets in test_loader:
        target_predicted = model(features[...,0], features[...,1])
        movie_names = get_movie(features[...,1].numpy())
        loss = criterion(target_predicted, targets)
        print(loss)
        target_predicted = target_predicted.squeeze().cpu().numpy()
        user_idx = features[...,0].cpu().numpy() 
        movies_idx = features[...,1].cpu().numpy()  
        target_real = targets.squeeze().cpu().numpy()
        #target_predicted  
        pred_df = pd.DataFrame(list(zip(user_idx, movies_idx, movie_names, target_real, target_predicted)))
        break
pred_df.head(20)
```

    tensor(0.7353)
    





  <div id="df-c0a4daa0-8ac8-4644-8695-376b7a7770d6">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>746</td>
      <td>418</td>
      <td>Mary Poppins (1964)</td>
      <td>5.0</td>
      <td>3.960400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>777</td>
      <td>404</td>
      <td>Mission: Impossible (1996)</td>
      <td>3.0</td>
      <td>2.279045</td>
    </tr>
    <tr>
      <th>2</th>
      <td>785</td>
      <td>230</td>
      <td>Batman Returns (1992)</td>
      <td>2.0</td>
      <td>3.065361</td>
    </tr>
    <tr>
      <th>3</th>
      <td>879</td>
      <td>139</td>
      <td>Homeward Bound: The Incredible Journey (1993)</td>
      <td>4.0</td>
      <td>3.125930</td>
    </tr>
    <tr>
      <th>4</th>
      <td>23</td>
      <td>257</td>
      <td>Contact (1997)</td>
      <td>4.0</td>
      <td>4.397166</td>
    </tr>
    <tr>
      <th>5</th>
      <td>303</td>
      <td>680</td>
      <td>Wishmaster (1997)</td>
      <td>2.0</td>
      <td>2.716514</td>
    </tr>
    <tr>
      <th>6</th>
      <td>59</td>
      <td>135</td>
      <td>Mr. Smith Goes to Washington (1939)</td>
      <td>4.0</td>
      <td>4.160026</td>
    </tr>
    <tr>
      <th>7</th>
      <td>415</td>
      <td>14</td>
      <td>Mr. Holland's Opus (1995)</td>
      <td>4.0</td>
      <td>4.215237</td>
    </tr>
    <tr>
      <th>8</th>
      <td>739</td>
      <td>331</td>
      <td>Kiss the Girls (1997)</td>
      <td>3.0</td>
      <td>3.314857</td>
    </tr>
    <tr>
      <th>9</th>
      <td>886</td>
      <td>430</td>
      <td>Highlander (1986)</td>
      <td>3.0</td>
      <td>4.366575</td>
    </tr>
    <tr>
      <th>10</th>
      <td>933</td>
      <td>68</td>
      <td>Forrest Gump (1994)</td>
      <td>5.0</td>
      <td>3.462778</td>
    </tr>
    <tr>
      <th>11</th>
      <td>84</td>
      <td>41</td>
      <td>Clerks (1994)</td>
      <td>3.0</td>
      <td>3.208103</td>
    </tr>
    <tr>
      <th>12</th>
      <td>881</td>
      <td>242</td>
      <td>Jungle2Jungle (1997)</td>
      <td>4.0</td>
      <td>2.592931</td>
    </tr>
    <tr>
      <th>13</th>
      <td>12</td>
      <td>910</td>
      <td>Twilight (1998)</td>
      <td>2.0</td>
      <td>2.822413</td>
    </tr>
    <tr>
      <th>14</th>
      <td>393</td>
      <td>402</td>
      <td>Batman (1989)</td>
      <td>4.0</td>
      <td>3.974622</td>
    </tr>
    <tr>
      <th>15</th>
      <td>404</td>
      <td>591</td>
      <td>True Crime (1995)</td>
      <td>1.0</td>
      <td>1.466990</td>
    </tr>
    <tr>
      <th>16</th>
      <td>637</td>
      <td>509</td>
      <td>Magnificent Seven, The (1954)</td>
      <td>3.0</td>
      <td>3.588601</td>
    </tr>
    <tr>
      <th>17</th>
      <td>486</td>
      <td>540</td>
      <td>Mortal Kombat (1995)</td>
      <td>3.0</td>
      <td>2.984062</td>
    </tr>
    <tr>
      <th>18</th>
      <td>270</td>
      <td>413</td>
      <td>My Favorite Year (1982)</td>
      <td>4.0</td>
      <td>3.552820</td>
    </tr>
    <tr>
      <th>19</th>
      <td>343</td>
      <td>123</td>
      <td>Lone Star (1996)</td>
      <td>5.0</td>
      <td>4.303177</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-c0a4daa0-8ac8-4644-8695-376b7a7770d6')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-c0a4daa0-8ac8-4644-8695-376b7a7770d6 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-c0a4daa0-8ac8-4644-8695-376b7a7770d6');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
# lowest
movie_bias = model.movie_bias.weight
idxs = movie_bias.argsort(0)[:5].squeeze().numpy()
get_movie(idxs)
```




    ['Children of the Corn: The Gathering (1996)',
     'Lawnmower Man 2: Beyond Cyberspace (1996)',
     'Mortal Kombat: Annihilation (1997)',
     'Jury Duty (1995)',
     'Striptease (1996)']




```python
# highest
idxs = movie_bias.argsort(0, descending=True)[:5].squeeze().numpy()
get_movie(idxs)
```




    ["Schindler's List (1993)",
     'Shawshank Redemption, The (1994)',
     'Casablanca (1942)',
     'Rear Window (1954)',
     'Star Wars (1977)']



## Get top k favourite movies


```python
# get top k movies that have 
def get_top_k(k):
  with torch.no_grad():
    all_bias = model.movie_bias(torch.tensor(np.arange(n_movies), device=device))
  idx = all_bias.squeeze().cpu().argsort(descending=True)[:k].squeeze().numpy()
  return get_movie(idx), idx
k_name, k_idx = get_top_k(40)
k_name
```




    ["Schindler's List (1993)",
     'Shawshank Redemption, The (1994)',
     'Casablanca (1942)',
     'Rear Window (1954)',
     'Star Wars (1977)',
     'Close Shave, A (1995)',
     'Usual Suspects, The (1995)',
     'Wrong Trousers, The (1993)',
     'Silence of the Lambs, The (1991)',
     'Good Will Hunting (1997)',
     'Raiders of the Lost Ark (1981)',
     'North by Northwest (1959)',
     "One Flew Over the Cuckoo's Nest (1975)",
     'Vertigo (1958)',
     'Titanic (1997)',
     'L.A. Confidential (1997)',
     'Godfather, The (1972)',
     'Boot, Das (1981)',
     'To Kill a Mockingbird (1962)',
     '12 Angry Men (1957)',
     'Wallace & Gromit: The Best of Aardman Animation (1996)',
     'Manchurian Candidate, The (1962)',
     'As Good As It Gets (1997)',
     'Third Man, The (1949)',
     'Citizen Kane (1941)',
     'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)',
     'Secrets & Lies (1996)',
     "It's a Wonderful Life (1946)",
     'Empire Strikes Back, The (1980)',
     'Fargo (1996)',
     'Henry V (1989)',
     'Blade Runner (1982)',
     'Amadeus (1984)',
     'Braveheart (1995)',
     'Bridge on the River Kwai, The (1957)',
     'Princess Bride, The (1987)',
     'Maltese Falcon, The (1941)',
     'African Queen, The (1951)',
     'Glory (1989)',
     'Wizard of Oz, The (1939)']



## Visualize top k movies


```python
with torch.no_grad():
  movie_factors = model.movie_factors(torch.tensor(np.arange(n_movies), device=device)).cpu().numpy()
```


```python
pca = PCA(n_components=3)
pca.fit(movie_factors)
reduced_embed = pca.transform(movie_factors)
X = reduced_embed[k_idx][:,0]
Y = reduced_embed[k_idx][:,2]
plt.figure(figsize=(15,15))
plt.scatter(X, Y)
for i, x, y in zip(k_name,X, Y):
    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)
```


    
![png](/assets/images/cf/output_32_0.png)
    


## Get distance between 2 movies


```python
def movie_o2i(s):
  return movies[movies["title"] == s]["movie"].values
```


```python
# get the closest movie
def get_closest_movie(s1):
  i1 = torch.tensor(movie_o2i(s1))
  movie_factors_torch = torch.tensor(movie_factors)
  distances = nn.CosineSimilarity(dim=1)(movie_factors_torch, movie_factors_torch[i1])

  idx = distances.argsort(descending=True)[:6].squeeze().numpy()
  print(idx)
  return get_movie(idx)

s1 = 'Silence of the Lambs, The (1991)'
get_closest_movie(s1)
```

    [  97  606  271  533  836 1355]
    




    ['Silence of the Lambs, The (1991)',
     'Rebecca (1940)',
     'Good Will Hunting (1997)',
     'Traveller (1997)',
     'Meet John Doe (1941)',
     "Ed's Next Move (1996)"]




```python
s1 = 'Snow White and the Seven Dwarfs (1937)' # kids movie
get_closest_movie(s1)
```

    [ 98 403 500 431 841 135]
    




    ['Snow White and the Seven Dwarfs (1937)',
     'Pinocchio (1940)',
     'Dumbo (1941)',
     'Fantasia (1940)',
     'Pollyanna (1960)',
     'Mr. Smith Goes to Washington (1939)']




```python
s1 = 'Star Wars (1977)' # the first 2 suggested films are actually star wars film
get_closest_movie(s1)
```

    [ 49 171 180 173 108 122]
    




    ['Star Wars (1977)',
     'Empire Strikes Back, The (1980)',
     'Return of the Jedi (1983)',
     'Raiders of the Lost Ark (1981)',
     'Mystery Science Theater 3000: The Movie (1996)',
     'Frighteners, The (1996)']




```python

```
